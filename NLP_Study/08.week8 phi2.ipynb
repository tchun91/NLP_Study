{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1dec0e0a35ac470c8ab76d774376d915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95a3bc66eb924183811614b53726a02b",
              "IPY_MODEL_5731230a1aae4e62ba1e249e989e6763",
              "IPY_MODEL_6d56633ce343477da8555c0570d9e7d5"
            ],
            "layout": "IPY_MODEL_dcf870cce8344bc3bab53324af8e6ff5"
          }
        },
        "95a3bc66eb924183811614b53726a02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c664a9d6f074c3baeca1e486ce523f6",
            "placeholder": "​",
            "style": "IPY_MODEL_9e5e8fb27dc54b3a890a048a72e7161e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5731230a1aae4e62ba1e249e989e6763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7b3d3fa0a8f4076b06b99aaa37637ed",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac5c9cf930944a6f97efcc71e5340bff",
            "value": 2
          }
        },
        "6d56633ce343477da8555c0570d9e7d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a860aa1739364f3fac8b0cc8f9451fa6",
            "placeholder": "​",
            "style": "IPY_MODEL_fbf772d15d3d4ecdafa340669ecdd357",
            "value": " 2/2 [00:38&lt;00:00, 16.66s/it]"
          }
        },
        "dcf870cce8344bc3bab53324af8e6ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c664a9d6f074c3baeca1e486ce523f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5e8fb27dc54b3a890a048a72e7161e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7b3d3fa0a8f4076b06b99aaa37637ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5c9cf930944a6f97efcc71e5340bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a860aa1739364f3fac8b0cc8f9451fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf772d15d3d4ecdafa340669ecdd357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66289124caba44efb7fba8a7b9f2f196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4811325dc2c42aca2ce24b4bafa5b6f",
              "IPY_MODEL_750be3a331284849a57889dcbb09f7e2",
              "IPY_MODEL_e66cc77ed949403d914d7da379384521"
            ],
            "layout": "IPY_MODEL_5d4698030afb4371ae1f33e3fc1f8c34"
          }
        },
        "f4811325dc2c42aca2ce24b4bafa5b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f02ce3181c3c482ba632041bff228af9",
            "placeholder": "​",
            "style": "IPY_MODEL_5670c5ecde524181b9cc204a79c6daa9",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "750be3a331284849a57889dcbb09f7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681ceb529210489b91bdc21fa1279413",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68ca695b24be45c7a85821091c37eff0",
            "value": 772
          }
        },
        "e66cc77ed949403d914d7da379384521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0d9604494c49d9bf4049c1707c0d1f",
            "placeholder": "​",
            "style": "IPY_MODEL_498deae95352477d9b4841ad0ee305ff",
            "value": " 772/772 [00:41&lt;00:00, 16.66 examples/s]"
          }
        },
        "5d4698030afb4371ae1f33e3fc1f8c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02ce3181c3c482ba632041bff228af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5670c5ecde524181b9cc204a79c6daa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "681ceb529210489b91bdc21fa1279413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ca695b24be45c7a85821091c37eff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea0d9604494c49d9bf4049c1707c0d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498deae95352477d9b4841ad0ee305ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ec90f8392ff4c95a0754b5c778ae690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fd0380dcffc4eb9ad3b12e691abc011",
              "IPY_MODEL_461b4cffb42b46769c5d5a13359e2954",
              "IPY_MODEL_afeaa753a2e546a1b0b047bd46515c25"
            ],
            "layout": "IPY_MODEL_28bbc67dd3db425485d2ee866df34027"
          }
        },
        "9fd0380dcffc4eb9ad3b12e691abc011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8513eb5170147bdb055698514d7b4b6",
            "placeholder": "​",
            "style": "IPY_MODEL_80b0905693c140c7a4054466076e9c01",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "461b4cffb42b46769c5d5a13359e2954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eef612a425a14657955ed4a7c0553e55",
            "max": 193,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2128b04d7db44bcaa928c7b5f3fb13ae",
            "value": 193
          }
        },
        "afeaa753a2e546a1b0b047bd46515c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0804ecfddc284c89b4f64b0a9af90803",
            "placeholder": "​",
            "style": "IPY_MODEL_6e59ff36a9f640b3941bc8f50458e645",
            "value": " 193/193 [00:10&lt;00:00, 30.22 examples/s]"
          }
        },
        "28bbc67dd3db425485d2ee866df34027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8513eb5170147bdb055698514d7b4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b0905693c140c7a4054466076e9c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eef612a425a14657955ed4a7c0553e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2128b04d7db44bcaa928c7b5f3fb13ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0804ecfddc284c89b4f64b0a9af90803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e59ff36a9f640b3941bc8f50458e645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install accelerate==0.26.1\n",
        "%pip install bitsandbytes==0.42.0\n",
        "%pip install datasets==2.16.1\n",
        "%pip install peft==0.8.1\n",
        "%pip install transformers==4.37.2\n",
        "%pip install einops==0.7.0\n",
        "%pip install torch==2.1.0\n",
        "%pip uninstall -y transformers && pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7-D8XJa9zkp",
        "outputId": "b12528e0-43e3-410a-b35a-d92f2fcd6a5d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate==0.26.1 in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.26.1) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.26.1) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.26.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.26.1) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.26.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.26.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.26.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.26.1) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.26.1) (1.3.0)\n",
            "Requirement already satisfied: bitsandbytes==0.42.0 in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.42.0) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes==0.42.0) (1.25.2)\n",
            "Requirement already satisfied: datasets==2.16.1 in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.16.1) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.16.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.16.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.16.1) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.16.0)\n",
            "Requirement already satisfied: peft==0.8.1 in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (2.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (4.37.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (4.66.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (0.26.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.8.1) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.8.1) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.8.1) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.8.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.8.1) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.8.1) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.8.1) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.8.1) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.8.1) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.8.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.1) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.8.1) (1.3.0)\n",
            "Requirement already satisfied: transformers==4.37.2 in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (2024.2.2)\n",
            "Requirement already satisfied: einops==0.7.0 in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Found existing installation: transformers 4.37.2\n",
            "Uninstalling transformers-4.37.2:\n",
            "  Successfully uninstalled transformers-4.37.2\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-bmhfw10b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-bmhfw10b\n",
            "  Resolved https://github.com/huggingface/transformers to commit 8c12690cecbb97e187861e386f7a0ac790e4236c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (2.31.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.0.dev0)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.41.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.41.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0.dev0) (2024.2.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.41.0.dev0-py3-none-any.whl size=9012708 sha256=e53eccf61b89e7dda552a23dd2988b619b8cb0696341f46511d3016a51873891\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8dzq9r1g/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "Successfully installed tokenizers-0.19.1 transformers-4.41.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1dec0e0a35ac470c8ab76d774376d915",
            "95a3bc66eb924183811614b53726a02b",
            "5731230a1aae4e62ba1e249e989e6763",
            "6d56633ce343477da8555c0570d9e7d5",
            "dcf870cce8344bc3bab53324af8e6ff5",
            "7c664a9d6f074c3baeca1e486ce523f6",
            "9e5e8fb27dc54b3a890a048a72e7161e",
            "b7b3d3fa0a8f4076b06b99aaa37637ed",
            "ac5c9cf930944a6f97efcc71e5340bff",
            "a860aa1739364f3fac8b0cc8f9451fa6",
            "fbf772d15d3d4ecdafa340669ecdd357"
          ]
        },
        "id": "Oi_XJojT9eTH",
        "outputId": "d5d5e6ff-4b63-4e86-bc99-2b0957b559c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dec0e0a35ac470c8ab76d774376d915"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "# Load model\n",
        "modelpath = \"microsoft/phi-2\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    modelpath,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "    ),\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    # FA2 does not work yet\n",
        "    # attn_implementation=\"flash_attention_2\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# fast tokenizer sometimes ignores the added tokens\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelpath, use_fast=False)\n",
        "\n",
        "# add special tokens for ChatML formatting and a pad token\n",
        "tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n",
        "tokenizer.pad_token = \"<PAD>\"\n",
        "tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n",
        "model.config.eos_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqtNZEyG_CES",
        "outputId": "435263b7-8467-40b8-c659-3af5c3271eaa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
        "\n",
        "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
        "\n",
        "# Adapter settings\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    target_modules = [ \"q_proj\", \"k_proj\", \"v_proj\", \"dense\" ],\n",
        "    modules_to_save = [\"lm_head\", \"embed_tokens\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "model.config.use_cache = False\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# load the dataset created in Part 1\n",
        "dataset = load_dataset(\"g-ronimo/riddles_evolved\")\n",
        "\n",
        "# split into training (90%) and test set (10%)\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1)"
      ],
      "metadata": {
        "id": "ll6030ag_CB-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "posts_df = pd.read_csv('reddit.csv')\n",
        "\n",
        "posts_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "t00D-mZw_B_q",
        "outputId": "4fff44a5-3aa5-400e-e945-5455d0f1df36"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 title  \\\n",
              "0    Ford And GM Are Running Back To Trucks As EV D...   \n",
              "1    Toyota's Hydrogen Future Is Crumbling As Owner...   \n",
              "2    F1 Drivers Surprised by China Track That's Bee...   \n",
              "3    All the Incredible Cars Destroyed in Cash for ...   \n",
              "4    Have I lost my mind? I kind of want a Camry as...   \n",
              "..                                                 ...   \n",
              "960  Do you think we have been spoiled by modern cars?   \n",
              "961  Hyundai’s Genesis brand is a dark horse in U.S...   \n",
              "962  Now that Toyota has LC300/LX, Prado/GX, Tundra...   \n",
              "963  Toyota USA museum is crushing a mint condition...   \n",
              "964  Rivian Builds 100,000th EV As R1T Becomes Top ...   \n",
              "\n",
              "                                                  body  \\\n",
              "0                                                  NaN   \n",
              "1                                                  NaN   \n",
              "2                                                  NaN   \n",
              "3    **Link:** https://www.youtube.com/watch?v=BUWj...   \n",
              "4    I just watched SavageGeese's video review on i...   \n",
              "..                                                 ...   \n",
              "960  So I find myself at an interesting point in my...   \n",
              "961                                                NaN   \n",
              "962  I think Toyota is the only manufacturer where ...   \n",
              "963                                                NaN   \n",
              "964                                                NaN   \n",
              "\n",
              "                                              comments  \\\n",
              "0    [\"Ah yes, we all remember when GM and Ford lef...   \n",
              "1    [\"Wow I never knew how bad the fuel problem ha...   \n",
              "2    [\"First world power with third world practical...   \n",
              "3    [\"times were tough. I hade to trade is my gas ...   \n",
              "4    [\"“I want one of the most common daily drivers...   \n",
              "..                                                 ...   \n",
              "960  [\"In terms of sheer power, absolutely, we're s...   \n",
              "961  [\"Until Hyundai, Kia, and Genesis start enforc...   \n",
              "962  [\"Probably update them at some point? They’ve ...   \n",
              "963  [\"Article mentions potential liability reasons...   \n",
              "964  [\"This is good news. I like Rivian and hope th...   \n",
              "\n",
              "                                                     q  \\\n",
              "0    Ford And GM Are Running Back To Trucks As EV D...   \n",
              "1    Toyota's Hydrogen Future Is Crumbling As Owner...   \n",
              "2    F1 Drivers Surprised by China Track That's Bee...   \n",
              "3    All the Incredible Cars Destroyed in Cash for ...   \n",
              "4    Have I lost my mind? I kind of want a Camry as...   \n",
              "..                                                 ...   \n",
              "960  Do you think we have been spoiled by modern ca...   \n",
              "961  Hyundai’s Genesis brand is a dark horse in U.S...   \n",
              "962  Now that Toyota has LC300/LX, Prado/GX, Tundra...   \n",
              "963  Toyota USA museum is crushing a mint condition...   \n",
              "964  Rivian Builds 100,000th EV As R1T Becomes Top ...   \n",
              "\n",
              "                                                     a  \n",
              "0    Ah yes, we all remember when GM and Ford left ...  \n",
              "1    Wow I never knew how bad the fuel problem had ...  \n",
              "2    First world power with third world practicalit...  \n",
              "3    times were tough. I hade to trade is my gas gu...  \n",
              "4    “I want one of the most common daily drivers a...  \n",
              "..                                                 ...  \n",
              "960  In terms of sheer power, absolutely, we're spo...  \n",
              "961  Until Hyundai, Kia, and Genesis start enforcin...  \n",
              "962  Probably update them at some point? They’ve al...  \n",
              "963  Article mentions potential liability reasons t...  \n",
              "964  This is good news. I like Rivian and hope they...  \n",
              "\n",
              "[965 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d31aabd1-af0e-4215-a22b-b0baa496c9f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>comments</th>\n",
              "      <th>q</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ford And GM Are Running Back To Trucks As EV D...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"Ah yes, we all remember when GM and Ford lef...</td>\n",
              "      <td>Ford And GM Are Running Back To Trucks As EV D...</td>\n",
              "      <td>Ah yes, we all remember when GM and Ford left ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Toyota's Hydrogen Future Is Crumbling As Owner...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"Wow I never knew how bad the fuel problem ha...</td>\n",
              "      <td>Toyota's Hydrogen Future Is Crumbling As Owner...</td>\n",
              "      <td>Wow I never knew how bad the fuel problem had ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F1 Drivers Surprised by China Track That's Bee...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"First world power with third world practical...</td>\n",
              "      <td>F1 Drivers Surprised by China Track That's Bee...</td>\n",
              "      <td>First world power with third world practicalit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All the Incredible Cars Destroyed in Cash for ...</td>\n",
              "      <td>**Link:** https://www.youtube.com/watch?v=BUWj...</td>\n",
              "      <td>[\"times were tough. I hade to trade is my gas ...</td>\n",
              "      <td>All the Incredible Cars Destroyed in Cash for ...</td>\n",
              "      <td>times were tough. I hade to trade is my gas gu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have I lost my mind? I kind of want a Camry as...</td>\n",
              "      <td>I just watched SavageGeese's video review on i...</td>\n",
              "      <td>[\"“I want one of the most common daily drivers...</td>\n",
              "      <td>Have I lost my mind? I kind of want a Camry as...</td>\n",
              "      <td>“I want one of the most common daily drivers a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>Do you think we have been spoiled by modern cars?</td>\n",
              "      <td>So I find myself at an interesting point in my...</td>\n",
              "      <td>[\"In terms of sheer power, absolutely, we're s...</td>\n",
              "      <td>Do you think we have been spoiled by modern ca...</td>\n",
              "      <td>In terms of sheer power, absolutely, we're spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961</th>\n",
              "      <td>Hyundai’s Genesis brand is a dark horse in U.S...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"Until Hyundai, Kia, and Genesis start enforc...</td>\n",
              "      <td>Hyundai’s Genesis brand is a dark horse in U.S...</td>\n",
              "      <td>Until Hyundai, Kia, and Genesis start enforcin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>Now that Toyota has LC300/LX, Prado/GX, Tundra...</td>\n",
              "      <td>I think Toyota is the only manufacturer where ...</td>\n",
              "      <td>[\"Probably update them at some point? They’ve ...</td>\n",
              "      <td>Now that Toyota has LC300/LX, Prado/GX, Tundra...</td>\n",
              "      <td>Probably update them at some point? They’ve al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963</th>\n",
              "      <td>Toyota USA museum is crushing a mint condition...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"Article mentions potential liability reasons...</td>\n",
              "      <td>Toyota USA museum is crushing a mint condition...</td>\n",
              "      <td>Article mentions potential liability reasons t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>Rivian Builds 100,000th EV As R1T Becomes Top ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"This is good news. I like Rivian and hope th...</td>\n",
              "      <td>Rivian Builds 100,000th EV As R1T Becomes Top ...</td>\n",
              "      <td>This is good news. I like Rivian and hope they...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>965 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d31aabd1-af0e-4215-a22b-b0baa496c9f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d31aabd1-af0e-4215-a22b-b0baa496c9f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d31aabd1-af0e-4215-a22b-b0baa496c9f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0dd0dd3d-77c1-484a-b066-dcdef6a4cf70\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0dd0dd3d-77c1-484a-b066-dcdef6a4cf70')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0dd0dd3d-77c1-484a-b066-dcdef6a4cf70 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "posts_df",
              "summary": "{\n  \"name\": \"posts_df\",\n  \"rows\": 965,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 190,\n        \"samples\": [\n          \"What\\u2019s something you like about cars that almost everyone hates?\",\n          \"Has anyone else here noticed how old cars are a central plot element in so many of horror writer Stephen King's novels, short stories, and movies?\",\n          \"Isn't Ram's upcoming 1500 Ramcharger technically the PHEV with the world's longest range?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"Mine is that the moonroofs that slide over the top of the car instead of inside the body make the car look cheap. Especially on Audis.\",\n          \"They always publish horsepower but not torque for e-CVT hybrids. Which I found weird considering they do publish both hp and torque figures for their hybrid vehicle with actual transmission (F-150 Hybrid, Tundra/Sequoia, NSX etc). \",\n          \"Keep a lookout for Nivlac57's 62 Studebaker (+ truck and trailer) stolen in Florence SC along the I-95 corridor. https://www.youtube.com/watch?v=XCQkHVKkmpQ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"[\\\"In the market for a 2015-2017 Honda Aacord. I\\u2019ve looked at just two so far but when I\\u2019ve pulled the dipstick both have been discolored with a yellowish almost burnt oil look covering the entire dipstick. I\\u2019ve never seen this before in any car I\\u2019ve owned. What causes this?\\\",\\\"How does a FWD car with electronic stability behave when it loses traction and goes sideways?\\\\n\\\\nFor example, on a AWD vehicle, the car just goes straight along the direction of the steering wheel, but the vehicle body is diagonal.\\\",\\\"Question for Honda / Acura mechanics. \\\\n\\\\nI have a 2016 Acura RDX  with the 3.5 NA V6. it has 42,000 kilometers,  or about 26,000 miles. Timing belt service is recommended 7- 9 years. Should get it done due to age, or leave it alone because of the low mileage  ?\\\",\\\"Do you guys have modded cars, and if you do, do you want to sell them now or in the future?\\\\n\\\\nFor car buyers, would you be willing to modified vehicle?\\\\n\\\\nIf yes/no, why haven't you yet?\\\",\\\"Looking to buy a SUV but wondering which kind are the best for daily driving down gravel/dirt roads. This is my first car so I'm not sure what to look for. Price range of 35,000 to 45,000 CAD\\\",\\\"# Lemon Law for Cars purchased out of state\\\\n\\\\nHi Guys - I am looking for advice related to the lemon law in US for cars purchased outside the state.\\\\n\\\\nMy car has been in the shop for over 4 weeks now and I don't think, the dealership has been able to fix it nor has an answer on why my issue is happening and I am sure that they will not be able to fix this for next few more weeks.\\\\n\\\\nJust wanted to ignore discussing about model and manufacturer to ensure that we are deviating out of the topic, as this is a generic question related to Lemon Law and not specifically manufacturer or model related. Thanks for understanding.\\\\n\\\\nI live in Texas, but I purchased my car from a Colorado dealer about 10 months back. Texas Lemon law states that I should have purchased the car from a Texas dealer and need to live in Texas to be eligible to submit a Lemon law claim.\\\\n\\\\nI looked at Colorado Lemon law, but it does clearly mention anything regarding resident of Colorado or needs to be purchased from the dealer.\\\\n\\\\nI am now clear that I will not be able to file it under Texas lemon law, but can I submit a claim using Colorado Lemon law for buyback?\\\\n\\\\nAre there any other alternate options in my case?\\\\n\\\\nI would surely get in touch with an attorney, but before I waste money to discuss with an attorney, I am trying to understand this from anyone who went thru similar situation\\\\n\\\\nThanks in advance for your response.\\\",\\\"Why Central driving positions didn\\u2019t get more popular with mid-engine cars?\\\",\\\"[removed]\\\",\\\"What affects how stiff or comfortable a ride is more: shocks and struts or springs?\\\",\\\"How can a passenger take control of a car if the driver were to pass out? I have a car with push button start, electronic automatic transmission and electronically engaged parking brake. I'm afraid to test any methods out for fear of damaging my car.\\\",\\\"Can I find out what work was carried out/checked in a service?\\\\n\\\\nThe service was paid for by the car dealership that sold me the car a week ago, at a garage of their choosing, and I have reason to think they are trying to do little to no work on it to save costs. The garage would not give me any paperwork for the job afterwards, saying I need to ask the car dealership for it. And the car dealership is not answering my calls, texts, or emails.\\\\n\\\\nThe garage didn't even put a stamp in the driver's book for the service. I had to go back in and ask them for it\\\",\\\"[removed]\\\",\\\"I want to buy a Miata but it wouldn\\u2019t be daily driven. I don\\u2019t have a garage, so I was planning to just leave it outside for winter. How bad is it for the car? Assuming that I don\\u2019t let the snow pile up on the soft top. And using a car cover too I suppose\\\",\\\"What current model, new, off the lot, but most importantly: FAST car would be your choice for rooftop tent camping? I'm talking something that rips on the street and on gravel, but sits too low to be an off roader.\\\",\\\"For those who went from a luxury to non luxury, what was it and why?\\\",\\\"Does anyone have AAA Premier that have their car towed? I was never asked for name, identification, or to sign any papers. I thought it was bizarre as this could easily be abusable where you can just use your membership for friends who need roadside assistance but don't have membership.\\\",\\\"Does FWD Subaru still uses longitudinal configuration?\\\",\\\"I just bought a 2001 Nissan Maxima, and I was just wondering what type of oil I should use for it?\\\",\\\"Hi there! Can someone recommend a budget friendly transport?\\\\n\\\\nJust moved cross country recently to move in with my partner, car is still in my home state as we wanted my family's mechanic to look it over and do some maintenance before we brought it down.\\\\n\\\\nDistance would be Connecticut to Florida.\\\\n\\\\nI did input my number into one of those quotes sites a while back, thinking it was for one company. I ended up with a lot of spam texts and calls - most of the places had weird reviews, including only charging a couple hundred dollars then upping the price and adding fees, or holding the car.\\\\n\\\\nI know to expect it'll be a bit expensive, but can someone recommend some of the more low budget companies that would be trustworthy? It's an old Hyundai Sonata, 2005, runs fine.\\\",\\\"I'm thinking about getting a convertible. I'm not too concerned about having room for human passengers or cargo space (as long as I can haul a couple suitcases or bags from a typical grocery run). However, I do have a 50-pound dog and 2 cats. I have a crash-tested seatbelt harness for the dog to wear, and I'm ordering a crash-tested carrier for each cat, which also must be buckled in to be effective. I can therefore only consider convertibles with passenger seats in the rear, right? This would assume the dog rides up front and the cats are in the back. I don't often drive all 3 pets around at once, but I need to have the option for vet visits etc.\\\",\\\"I'm looking for the exact thing I'm asking for, and not something similar. I already know about the similar options.  \\\\nI'm wondering if anyone knows of a way to connect the obd2 port directly to a cell phone with a cable. I don't want a wifi or bluetooth obd2 adapter device, and I don't want a dedicated obd2 scanner with a built-in display.  \\\\n I would like to find a cable with an obd2 port connector on one end, and a micro-usb or usb-c connector on the other end, or something comparable.  \\\\nIdeally, this cable would also charge the cell phone.  \\\\nDoes such a thing exist? I've been looking around, but haven't had any luck yet. I figured crowd-sourcing this might be a lot easier.\\\"]\",\n          \"[\\\"At what point does a faster electric vehicle not matter anymore? Base models outperform ICE exotics in a straight line on the regular these days.\\\",\\\"The last Mach E GT couldn\\u2019t sustain repeated performance without neutering itself. Hopefully that is fixed.\\\",\\\"New rear motor means more performance and range. \\\\n\\\\nGT with Performance Upgrade:\\\\n- 0-60 in 3.3s\\\\n- Quarter mile in 11.8 @ 114 mph\\\\n- 700 ft lbs torque (HP is still 480)\\\\n- 10-80% charge in 36.2 mins (8.8 mins faster than previous versions)\\\\n- 10 mile/16 km range improvement in the GT\\\",\\\"It\\u2019s PR.  If it wasn\\u2019t faster, it would be \\u201cthe best selling\\u2026\\u201d.  If it wasn\\u2019t that, it would be \\u201cthe only electric car that offers X or class leading Y\\u201d.\\\\n\\\\nAs a car guy, however, I\\u2019m fine with Manufacturers using performance as a benchmark.  \\u201cI wish my car was slower and less responsive\\u201d said no one, ever!\\\",\\\"I'm excited to see what the rally version can do.\\\",\\\"Faster but zero soul\\\",\\\"Now with even faster depreciation!\\\",\\\"I\\u2019ll put it simply, which electric cars have driving enthusiast character?\\\",\\\"The fact that Ford named this vehicle Mustang is a travesty.\\\",\\\"About time the car could make a 1/4 mile pass at full throttle. It was embarrassing that a car with the mustang name couldn\\u2019t\\\",\\\"Cool! My toaster cooks pop tarts a second faster! Who cares? These speeds are dumb at this point.\\\",\\\"The base GT is like $54k with no federal tax credit. The ralleye is $60k with no tax credit. The Y performance is $42k with the tax credit +$7500 without. Hard to justify the price difference for more speed alone.\\\",\\\"Neither cars are desirable to own, one took a famous automotive name and turned it to an suv and the other belongs to a company with terrible dealer/service infrastructure and terrible reliability\\\",\\\"I thought it said selling faster. Then I actually read the title and lost all interest. No one cares how fast a brick can fly in a straight line\\\",\\\"I've found that it doesn't really matter. The EV is fun for a bit, but it gets boring.\\\",\\\"[deleted]\\\",\\\"[removed]\\\",\\\"Electric cars are already fast enough (too fast to be useable on a daily baisis), how about improving weight, handling, cost, reliability etc? Would add much more value\\\",\\\"I don't care if it's faster. Is it a good EV? Is it affordable? Does it have good range? Can I charge it up in under 10 minutes anywhere?\\\",\\\"And?\\\",\\\"Does it still slog after 60 MPH?\\\",\\\"Honestly no one cares about fast \\\\n\\\\nWhat they care about is that it's not crazy heavy \\\\n\\\\nThat has a good range \\\\n\\\\nAnd it's well supported by the current manufacturer \\\\n\\\\nAnd it's reasonably priced\\\",\\\"Who cares.\\\",\\\"Yes because we need super fast crossover things.\\\",\\\"Ford giving their very first EV the Mustang nameplate was the biggest blunder they could\\u2019ve made when rolling out this vehicle. I think it\\u2019s a good looking vehicle but it lacks an identity or presence.\\\",\\\"And it\\u2019s faster than a Club Car! But as exciting as a melting ice cube.\\\",\\\"Okay.\\\",\\\"Who cares?  Speed limits still exist. It's not like it's taking it 60 seconds to get to 60.\\\",\\\"Ford also said that I was gay, they have been saying a lot of things lately\\\",\\\"It's not a mustang but okay\\\",\\\"It\\u2019s a Ford so fastest to the side of the road.\\\",\\\"No one cares which ev is faster. ICE cars can be easily and modified and tuned by amateur mechanics. Competing with your buddy tuning and building your own car is the real competition in autosports.\\\",\\\"Whatever it\\u2019s not a mustang if its a suv\\\",\\\"Who on earth cares about who's commuter car is faster? an 8 second 0-60, with a top speed of 85 is all anybody needs in 99.99% of situations.\\\",\\\"Am I crazy or does it seem like the EV thing has hit a lull. Sales down bigly\\\",\\\"Yes but which one is uglier? It's tough to say as they are both very ugly.\\\",\\\"Christ. We are at a point where charging speed is a  performance stat?  Thanks, I hate it.\\\",\\\"I\\u2019d rather have top speed than acceleration.\\\",\\\"Let's count all the fucks I give.\\u00a0\\\",\\\"Tesla Y goes 0-60 in 3.6 seconds\\\\n\\\\n\\\\nFords not even close\\\",\\\"What\\u2019s the point of making fast EVs for driver\\u2019s enjoyment if they want to make driving illegal by next year?\\\"]\",\n          \"[\\\"Ok but what we really need to know from Top Gear is whether it's faster than a train ride across Romania and how well it handles the Australian outback.\\\",\\\"That new interior is *such* an upgrade.\\\",\\\"I think I'm one of the few who much prefers the db12 looks to db11. Db11 just looked kinda off, and boring to me. Something about the tail lights and the front bumper.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 192,\n        \"samples\": [\n          \"General question Wednesday: Ask your general car-related question and maybe someone will have an answer. **Please direct all choosing/purchase questions to the weekly car-buying sticky. All rules of** r/cars **apply here.**\",\n          \"Ford Says the 2024 Mustang Mach-E is Faster Than a Tesla Model Y \",\n          \"FIRST DRIVE: 671bhp Aston Martin DB12 Volante (Top Gear) [Video link](https://www.youtube.com/watch?v=1iYIm76xQBs)\\n\\nA good-looking car with an expected drop-top variant. Initial thoughts:\\n\\n* **Big** step up from the DB11 inside. It actually looks like a quarter million dollar interior now. It seems like they sorted out the early software issues with the infotainment. That said, what I thought when the first photos of the new interior came out is true. The angle of the center console catches the sun in just the right way to make the screen and many of the buttons illegible with the top down.\\n\\n* It's still a pretty car, but the DB11 was better looking IMO. The DB12 has shifted too far toward looking aggressive in the front rather than elegant. But the sides and rear are still elegant so it's a bit of a strange combo. The Roma is prettier now IMO, which is interesting because it just looks like a [DB10 copy](https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fxsaacwaucw051.png%3Fwidth%3D613%26auto%3Dwebp%26s%3D0cd4301d8475978464d60a8c77351767a085b7f7) to me.\\n\\n* The suspension still looks too stiff for a grand tourer (if I picture myself as the buyer at least). That was a common complaint about the coupe (Top Gear, Autocar, and Evo all said it in their reviews). Given the compromises of a convertible it's not likely Aston Martin made it any softer than the coupe.\\n\\n* Overall though I'm glad companies are still investing in this segment and the Aston Martin's efforts with the DB12 are clear. I think it's an improvement over the DB11 and something you don't have to make excuses for anymore.\\n\\nOn another note, despite Lawrence Stroll's comments about keeping combustion engines, it's known that they're working on an [electric grand tourer](https://www.caranddriver.com/news/a60471219/aston-martin-electric-car-production-plans-revealed/) which I'm really curious to see. That, the Rolls Royce Spectre, Maserati Granturismo Folgore, the upcoming Bentley Continental GT, Polestar 6, and maybe Genesis X will be the next step in the evolution of the segment as 12 cylinder engines effectively get replaced with electric motors. While that's an execution-worthy crime for this sub, I'm really interested to see how auto makers will approach it differently and what the reception from the press and buyers will be like.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 193,\n        \"samples\": [\n          \"In the market for a 2015-2017 Honda Aacord. I\\u2019ve looked at just two so far but when I\\u2019ve pulled the dipstick both have been discolored with a yellowish almost burnt oil look covering the entire dipstick. I\\u2019ve never seen this before in any car I\\u2019ve owned. What causes this?\",\n          \"At what point does a faster electric vehicle not matter anymore? Base models outperform ICE exotics in a straight line on the regular these days.\",\n          \"Ok but what we really need to know from Top Gear is whether it's faster than a train ride across Romania and how well it handles the Australian outback.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df,test_df = train_test_split(posts_df,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "Ei9KR8Va_B9P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "dataset_dict = datasets.DatasetDict()\n",
        "dataset_dict['train'] = datasets.Dataset.from_pandas(train_df)\n",
        "dataset_dict['test'] = datasets.Dataset.from_pandas(test_df)\n",
        "dataset_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLxtrLke_B6l",
        "outputId": "37014a33-e80b-46b5-e525-c4edff673d32"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['title', 'body', 'comments', 'q', 'a', '__index_level_0__'],\n",
              "        num_rows: 772\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['title', 'body', 'comments', 'q', 'a', '__index_level_0__'],\n",
              "        num_rows: 193\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from functools import partial\n",
        "\n",
        "# ChatML format\n",
        "templates = [\n",
        "    \"<|im_start|>assistant\\n{msg}<|im_end|>\",      # message by assistant\n",
        "    \"<|im_start|>user\\n{msg}<|im_end|>\"           # message by user\n",
        "]\n",
        "\n",
        "# This special index is used to ignore certain tokens during loss calculation.\n",
        "IGNORE_INDEX = -100\n",
        "\n",
        "def tokenize(input, max_length):\n",
        "    input_ids, attention_mask, labels, labels_mask = [], [], [],[]\n",
        "\n",
        "    # Iterate over each message in the dataset\n",
        "    for i, (msg,msg_a) in enumerate(zip(input['q'],input['a'])):\n",
        "\n",
        "        # Check if the message is from human (user) or assistant, apply ChatML template\n",
        "        isHuman = i%2==0\n",
        "        msg_chatml = templates[isHuman].format(msg=msg)\n",
        "        msg_chatml_a = templates[isHuman].format(msg=msg_a)\n",
        "\n",
        "        # tokenize all, truncate later\n",
        "        msg_tokenized = tokenizer(\n",
        "          msg_chatml,\n",
        "          truncation=False,\n",
        "          add_special_tokens=False)\n",
        "        msg_tokenized_a = tokenizer(\n",
        "          msg_chatml_a,\n",
        "          truncation=False,\n",
        "          add_special_tokens=False)\n",
        "        # Copy tokens and attention mask without changes\n",
        "        input_ids += msg_tokenized[\"input_ids\"]\n",
        "        attention_mask += msg_tokenized[\"attention_mask\"]\n",
        "\n",
        "        # Adapt labels for loss calculation: if user->IGNORE_INDEX, if assistant->input_ids  (=ignore human messages, calculate loss only for assistant messages since these are the reponses we want to learn)\n",
        "        # labels += [IGNORE_INDEX]*len(msg_tokenized[\"input_ids\"]) if isHuman else msg_tokenized[\"input_ids\"]\n",
        "        labels += msg_tokenized_a['input_ids']\n",
        "        labels_mask += msg_tokenized_a['attention_mask']\n",
        "\n",
        "    # truncate to max. length\n",
        "    return {\n",
        "        \"input_ids\": input_ids[:max_length],\n",
        "        \"attention_mask\": attention_mask[:max_length],\n",
        "        \"labels\": labels[:max_length],\n",
        "        'labels_mask':labels_mask[:max_length]\n",
        "    }\n",
        "\n",
        "dataset_tokenized = dataset_dict.map(\n",
        "    # cut samples at 1024 tokens\n",
        "    # enough for the riddles dataset (max. length ~1000 tokens)\n",
        "    # has to be adapted for other datasets, higher = more VRAM needed\n",
        "    partial(tokenize, max_length=1024),\n",
        "    batched = False,\n",
        "    num_proc = os.cpu_count(),    # multithreaded\n",
        "    # remove_columns = dataset_dict[\"train\"].column_names  # Remove original columns, no longer needed\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "66289124caba44efb7fba8a7b9f2f196",
            "f4811325dc2c42aca2ce24b4bafa5b6f",
            "750be3a331284849a57889dcbb09f7e2",
            "e66cc77ed949403d914d7da379384521",
            "5d4698030afb4371ae1f33e3fc1f8c34",
            "f02ce3181c3c482ba632041bff228af9",
            "5670c5ecde524181b9cc204a79c6daa9",
            "681ceb529210489b91bdc21fa1279413",
            "68ca695b24be45c7a85821091c37eff0",
            "ea0d9604494c49d9bf4049c1707c0d1f",
            "498deae95352477d9b4841ad0ee305ff",
            "6ec90f8392ff4c95a0754b5c778ae690",
            "9fd0380dcffc4eb9ad3b12e691abc011",
            "461b4cffb42b46769c5d5a13359e2954",
            "afeaa753a2e546a1b0b047bd46515c25",
            "28bbc67dd3db425485d2ee866df34027",
            "a8513eb5170147bdb055698514d7b4b6",
            "80b0905693c140c7a4054466076e9c01",
            "eef612a425a14657955ed4a7c0553e55",
            "2128b04d7db44bcaa928c7b5f3fb13ae",
            "0804ecfddc284c89b4f64b0a9af90803",
            "6e59ff36a9f640b3941bc8f50458e645"
          ]
        },
        "id": "pYiu4HAz_B07",
        "outputId": "8df1b20e-58ee-4dc8-c4b1-6748021783ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/772 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66289124caba44efb7fba8a7b9f2f196"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/193 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ec90f8392ff4c95a0754b5c778ae690"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collate function - to transform list of dictionaries [ {input_ids: [123, ..]}, {.. ] to a single dictionary forming a batch { input_ids: [..], labels: [..], attention_mask: [..] }\n",
        "def collate(elements):\n",
        "\n",
        "    # Extract input_ids from each element and find the maximum length among them\n",
        "    tokens = [e[\"input_ids\"] for e in elements]\n",
        "    tokens_maxlen = max([len(t) for t in tokens])\n",
        "\n",
        "    for i, sample in enumerate(elements):\n",
        "        input_ids = sample[\"input_ids\"]\n",
        "        labels = sample[\"labels\"]\n",
        "        attention_mask = sample[\"attention_mask\"]\n",
        "\n",
        "        # Calculate the padding length required to match the maximum token length\n",
        "        pad_len = tokens_maxlen-len(input_ids)\n",
        "\n",
        "        # Pad 'input_ids' with the pad token ID, 'labels' with IGNORE_INDEX, and 'attention_mask' with 0\n",
        "        input_ids.extend( pad_len * [tokenizer.pad_token_id] )\n",
        "        labels.extend( pad_len * [IGNORE_INDEX] )\n",
        "        attention_mask.extend( pad_len * [0] )\n",
        "\n",
        "    # create and return batch with all the data in elements\n",
        "    batch={\n",
        "        \"input_ids\": torch.tensor( [e[\"input_ids\"] for e in elements] ),\n",
        "        \"labels\": torch.tensor( [e[\"labels\"] for e in elements] ),\n",
        "        \"attention_mask\": torch.tensor( [e[\"attention_mask\"] for e in elements] ),\n",
        "    }\n",
        "    return batch"
      ],
      "metadata": {
        "id": "0sXRAzDv_Bp9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "bs=1         # batch size\n",
        "ga_steps=16  # gradient acc. steps\n",
        "epochs=20\n",
        "lr=0.00002\n",
        "\n",
        "steps_per_epoch=len(dataset_tokenized[\"train\"])//(bs*ga_steps)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"out\",\n",
        "    per_device_train_batch_size=bs,\n",
        "    per_device_eval_batch_size=16,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    logging_steps=1,\n",
        "    eval_steps=steps_per_epoch//2,      # eval twice per epoch\n",
        "    save_steps=steps_per_epoch,         # save once per epoch\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    num_train_epochs=epochs,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    optim=\"paged_adamw_32bit\",      # val_loss will go NaN with paged_adamw_8bit\n",
        "    learning_rate=lr,\n",
        "    group_by_length=False,\n",
        "    bf16=True,\n",
        "    ddp_find_unused_parameters=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=args,\n",
        "    data_collator=collate,\n",
        "    train_dataset=dataset_tokenized[\"train\"],\n",
        "    eval_dataset=dataset_tokenized[\"test\"],\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "XCl_9ZLvAA1a",
        "outputId": "60b198c3-26e0-4234-cbac-d254ac1296d7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Your setup doesn't support bf16/gpu. You need torch>=1.10, using Ampere GPU with cuda>=11.0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-711293e3c7a5>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_tokenized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mga_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m args = TrainingArguments(  \n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \u001b[0;31m# expand paths, if not os.makedirs(\"~/bar\") will make directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;31m# in the current directory instead of the actual home\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m         \u001b[0;31m# see https://github.com/huggingface/transformers/issues/10628\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Your setup doesn't support bf16/gpu. You need torch>=1.10, using Ampere GPU with cuda>=11.0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "eZO_pdBTATyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_t8N2u8yA4-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}